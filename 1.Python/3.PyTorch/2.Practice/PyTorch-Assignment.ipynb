{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font color='blue'>PyTorch Assignment<\/font>\n",
                "\n",
                "You have to implement ReLU, Softmax, and Neuron using PyTorch. Most probably, you have already implemented these functions using NumPy in the NumPy assignment. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font color='blue'>Marking Scheme<\/font>\n",
                "\n",
                "#### Maximum Points: 30\n",
                "\n",
                "<div>\n",
                "    <table>\n",
                "        <tr><td><h3>Sr. no.<\/h3><\/td> <td><h3>Problem<\/h3><\/td> <td><h3>Points<\/h3><\/td> <\/tr>\n",
                "        <tr><td><h3>1<\/h3><\/td> <td><h3>ReLU Implementation<\/h3><\/td> <td><h3>5<\/h3><\/td> <\/tr>\n",
                "        <tr><td><h3>2<\/h3><\/td> <td><h3>Softmax Implementation<\/h3><\/td> <td><h3>10<\/h3><\/td> <\/tr>\n",
                "        <tr><td><h3>3<\/h3><\/td> <td><h3>Neuron Implementation<\/h3><\/td> <td><h3>15<\/h3><\/td> <\/tr>\n",
                "    <\/table>\n",
                "<\/div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "import torch"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font color='blue'>1. ReLU Implementation (5 Points)<\/font>\n",
                "\n",
                "**ReLU** stands for Rectified Linear Unit. It defined as follows:\n",
                "\n",
                "```\n",
                "z = max(0, x)\n",
                "```\n",
                "\n",
                "\n",
                "<img src='https:\/\/www.learnopencv.com\/wp-content\/uploads\/2020\/01\/c3_w1_ReLU.png'\/>\n",
                "\n",
                "In this part, you have to implement this ReLU function definition for the NumPy array.\n",
                "\n",
                "So if the input is:\n",
                "```\n",
                "tensor([[ 1.0000,  2.0000, -3.0000],\n",
                "        [ 2.5000, -0.2000,  6.0000]])\n",
                "```\n",
                "\n",
                "You have to return the following output:\n",
                "```\n",
                "tensor([[1.0000, 2.0000, 0.0000],\n",
                "        [2.5000, 0.0000, 6.0000]])\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<div class=\"alert alert-block alert-info\">\n",
                "    <b>1. ReLU Implementation: 5 Points<\/b>\n",
                "<\/div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def ReLU(tensor):\n",
                "    \n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# test your result\n",
                "a = torch.tensor([[1, 2, -3], [2.5, -0.2, 6]])\n",
                "ReLU(a)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "ReLU Implementation",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font color='blue'>2. Softmax Implementation (10 Points)<\/font>\n",
                "\n",
                "Softmax is defined as follows:\n",
                "$$\n",
                "\\text{softmax}(z_{i}) = \\frac{\\exp(z_i)}{\\sum_j \\exp(z_j)}\n",
                "$$\n",
                "\n",
                "For example, we have following an array as an input:\n",
                "```\n",
                "tensor([0.6000, 5.2000, 9.2000])\n",
                "```\n",
                "\n",
                "Then, the function should return the following as output:\n",
                "```\n",
                "tensor([1.8076e-04, 1.7983e-02, 9.8184e-01])\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<div class=\"alert alert-block alert-info\">\n",
                "    <b>2. Softmax Implementation: 10 Points<\/b>\n",
                "<\/div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "def softmax(array):\n",
                "    \n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Test your result\n",
                "a = torch.tensor([0.6, 5.2, 9.2])\n",
                "softmax(a)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Softmax Implementation",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font color='blue'>3. Neural Network Neuron Implementation (15 Points)<\/font>\n",
                "\n",
                "\n",
                "We all are familiar with the `1-dimensional` linear equation:\n",
                "\n",
                "$$\n",
                "y = mx + c\n",
                "$$\n",
                "\n",
                "We can re-write the equation as:\n",
                "\n",
                "$$\n",
                "y = w_1x + b\n",
                "$$\n",
                "\n",
                "We can write the `n-dimensional` linear equation as follows:\n",
                "\n",
                "$$\n",
                "y = w_1x_1 + w_2x_2 + ... + w_nx_n + b\n",
                "$$\n",
                "\n",
                "\n",
                "Following is a pictorial representation `n-dimensional` linear equations. This linear function is called a neuron in neural networks. \n",
                "\n",
                "<img src='https:\/\/www.learnopencv.com\/wp-content\/uploads\/2020\/01\/c3_w1_linear_equation.png'>\n",
                "\n",
                "let's define $W$ as,\n",
                "$$\n",
                "W = \\begin{bmatrix}\n",
                "    w_1       & w_2 & w_3 & \\dots & w_n\n",
                "\\end{bmatrix}\n",
                "$$\n",
                "\n",
                "and $X$ as,\n",
                "$$\n",
                " X = \\begin{bmatrix}\n",
                "           x_{1} \\\\\n",
                "           x_{2} \\\\\n",
                "           \\vdots \\\\\n",
                "           x_{n}\n",
                "         \\end{bmatrix}\n",
                "$$\n",
                "\n",
                "Using above $W$ and $X$, we can re-write the n-dimensional linear equation as follows:\n",
                "\n",
                "$$\n",
                "y = WX + b\n",
                "$$\n",
                "\n",
                "In a neural network, $X$, $W$, $b$, and $y$ are called input, weight, bias, and output of the neuron, respectively. \n",
                "\n",
                "In a neural network, usually, we use to have much more than one neuron. The same input $X$ passes through all neurons of the layer and gets output $y$ for each neuron. We don't have to calculate linear function for each neuron at a time; we can calculate all in one go using Numpy.\n",
                "\n",
                "Let's assume we have `m` neurons. So we will have `m` output. Let's stack all weight horizontally and do matrix multiplication by input and add stacked $b$. It will give `m` output for all `m` neurons. \n",
                "\n",
                "\n",
                "$$\n",
                "W = \\begin{bmatrix}\n",
                "    w_{11}       & w_{12} & w_{13} & \\dots & w_{1n} \\\\\n",
                "    w_{21}       & w_{22} & w_{23} & \\dots & w_{2n} \\\\\n",
                "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
                "    w_{m1}       & w_{m2} & w_{m3} & \\dots & w_{mn}\n",
                "\\end{bmatrix}\n",
                "$$\n",
                "\n",
                "$$\n",
                " B = \\begin{bmatrix}\n",
                "           b_{1} \\\\\n",
                "           b_{2} \\\\\n",
                "           \\vdots \\\\\n",
                "           b_{m}\n",
                "         \\end{bmatrix}\n",
                "$$\n",
                "\n",
                "$$\n",
                " Y = \\begin{bmatrix}\n",
                "           y_{1} \\\\\n",
                "           y_{2} \\\\\n",
                "           \\vdots \\\\\n",
                "           y_{m}\n",
                "         \\end{bmatrix}\n",
                "$$\n",
                "\n",
                "You have to implement the following function:\n",
                "$$\n",
                "Y = WX + B\n",
                "$$\n",
                "The function will take weight $W$, bias $B$, and input $X$ as arguments. You have to return outputs $Y$.\n",
                "\n",
                "For example, arguments $W$, $B$ and $X$ are as follows:\n",
                "```\n",
                "W = tensor([[1.2000, 0.3000, 0.1000],\n",
                "            [0.0100, 2.1000, 0.7000]])\n",
                "B = tensor([2.1000, 0.8900])\n",
                "X = tensor([0.3000, 6.8000, 0.5900])\n",
                "```\n",
                "\n",
                "Function should return:\n",
                "```\n",
                "tensor([ 4.5590, 15.5860])\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<div class=\"alert alert-block alert-info\">\n",
                "    <b>3. Neuron Implementation: 15 Points<\/b>\n",
                "<\/div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": false,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "def neural_network_neurons(W, B, X):\n",
                "    \n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# test your code\n",
                "W = torch.tensor([[1.2, 0.3, 0.1], [.01, 2.1, 0.7]])\n",
                "B = torch.tensor([2.1, 0.89])\n",
                "X = torch.tensor([0.3, 6.8, 0.59])\n",
                "\n",
                "neural_network_neurons(W, B, X)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Neuron Implementation",
                    "locked": true,
                    "points": "15",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8",
            "language": "python",
            "name": "python38"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}