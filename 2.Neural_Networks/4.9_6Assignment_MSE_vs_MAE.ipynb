{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# <font color='blue'>Assignment: MSE-vs-MAE<\/font>\n",
                "\n",
                "In the lecture, we have seen that `Mean Absolute Error` (`MAE`) is more robust to outlier compare to `Mean Square Error` (`MSE`). In this assignment, we have to be a witness to this theory. \n",
                "\n",
                "Although we have an intuition that it is bound to happen because the cost of outliers is much more in `MSE` compare to `MAE`. Let's implement and witness it. \n",
                "\n",
                "**In this assignment, you have to implement the following:**\n",
                "\n",
                "- `Mean Square Error (MSE)`\n",
                "\n",
                "\n",
                "- `Mean Absolute Error (MAE)`\n",
                "\n",
                "\n",
                "- The gradient with respect to `m` and `c`, when the loss function is `MSE`\n",
                "\n",
                "\n",
                "- The gradient with respect to `m` and `c`, when the loss function is `MAE`\n",
                "\n",
                "Codes for training and visualization is already in the notebook."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font color='blue'>Marking Scheme<\/font>\n",
                "\n",
                "#### Maximum Points: 30\n",
                "\n",
                "<div>\n",
                "    <table>\n",
                "        <tr><td><h3>Sr. no.<\/h3><\/td> <td><h3>Problem<\/h3><\/td> <td><h3>Points<\/h3><\/td> <\/tr>\n",
                "        <tr><td><h3>1<\/h3><\/td> <td><h3>Mean Square Error (MSE)<\/h3><\/td> <td><h3>5<\/h3><\/td> <\/tr>\n",
                "        <tr><td><h3>2<\/h3><\/td> <td><h3>Mean Absolute Error (MAE)<\/h3><\/td> <td><h3>5<\/h3><\/td> <\/tr>\n",
                "        <tr><td><h3>3<\/h3><\/td> <td><h3>Gradients for MSE<\/h3><\/td> <td><h3>10<\/h3><\/td> <\/tr>\n",
                "        <tr><td><h3>4<\/h3><\/td> <td><h3>Gradients for MAE<\/h3><\/td> <td><h3>10<\/h3><\/td> <\/tr>\n",
                "    <\/table>\n",
                "<\/div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from collections import defaultdict\n",
                "\n",
                "\n",
                "plt.style.use('ggplot')\n",
                "\n",
                "torch.manual_seed(0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "plt.rcParams[\"figure.figsize\"] = (15, 8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# <font style=\"color:green\">1. Generate Data <\/font>\n",
                "We will generate 1000 data points for the experiment. The `x-axis` is the independent variable which has values randomly distributed between -5 to 5. We assume some values for m and c to create the data points for the dependent variable ( `y-axis` ). We also add some randomness so that the y values are different for the same x. \n",
                "\n",
                "Now, we have a simple dataset which has been generated using a linear model in the presence of noise. We have also converted five percent of data into outliers to observe the performance difference between MSE and MAE at the time of training. The data has been dispayed using the scatter plot."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Generating y = mx + c + random noise\n",
                "num_data = 1000\n",
                "\n",
                "# True values of m and c\n",
                "m_line = 3.3\n",
                "c_line = 5.3\n",
                "\n",
                "# input (Generate random data between [-5,5])\n",
                "x = 10 * torch.rand(num_data) - 5\n",
                "\n",
                "# Output (Generate data assuming y = mx + c + noise)\n",
                "y_label = m_line * x + c_line + torch.randn_like(x)\n",
                "\n",
                "# Add a few outlier\n",
                "num_outliers = int(0.05 * num_data)\n",
                "random_index = torch.randint(num_data, (num_outliers,))\n",
                "y_label[random_index] = 50 * torch.rand(len(random_index))\n",
                "\n",
                "y = m_line * x + c_line\n",
                "\n",
                "# Plot the generated data points \n",
                "plt.plot(x, y_label, '.', color='g', label=\"Data points\")\n",
                "plt.plot(x, y, color='b', label='y = mx + c', linewidth=3)\n",
                "plt.ylabel('y')\n",
                "plt.xlabel('x')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# <font style=\"color:green\">2. Problem Formulation<\/font>\n",
                "\n",
                "The goal is to predict $y$ given some value of $x$. To do this we will fit a line that goes through the data points $(x_i, y_i)$. The equation for such a line is \n",
                "\n",
                "$$\n",
                "y = mx + c\n",
                "$$\n",
                "\n",
                "We have a set of data points $(x_i, y_i)$, and they should all satisfy the equation above. i.e., \n",
                "\n",
                "$$\n",
                "y_i = m x_i + c\n",
                "$$\n",
                "\n",
                "Unless we have perfect data with no noise, even the best $m$ and $c$ we can find will not perfectly fit the data. So, we will have an **error** or a **residual** given by\n",
                "\n",
                "$$\n",
                "e_i = (y_i - m x_i -c) \n",
                "$$\n",
                "\n",
                "We want to find a value of $m$ and $c$ that minimizes the error above. Positive or negative values of error are equally bad for us. So, we are interested in minimizing the square or absolute of the error above. We will see the mean square error (`MSE`) and mean absolute error (`MAE`) and their gradients with respect to m and c. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# <font style=\"color:green\">3. Loss Functions and their Gradients wrt Learning Parameters.<\/font>\n",
                "\n",
                "We need a loss function that can be optimized using gradient descent and updating learnable parameters. Here, we will use two types of loss functions and see which is performing better in the case of outliers in the training data. \n",
                "\n",
                "\n",
                "## <font style=\"color:green\">3.1. Mean Square Error (MSE)<\/font>\n",
                "\n",
                "**The `mean squared error (MSE)` function which is given by:**\n",
                "\n",
                "$$\n",
                "l_{mse} = \\frac{1}{N}\\sum^N_{i=1}(y_i - m x_i -c)^2 \\\\\n",
                "$$\n",
                "\n",
                "**Take partial derivatives w.r.t `m` and `c` respectively:**\n",
                "\n",
                "$$\n",
                "\\begin{align}\n",
                "\\frac{\\partial l_{mse}}{\\partial m}  &= -\\frac{2}{N} \\sum^N_{i=1} x_i(y_i - m x_i - c) \\\\\n",
                "\\frac{\\partial l_{mse}}{\\partial c}  &= -\\frac{2}{N} \\sum^N_{i=1} (y_i - m x_i - c) \\\\\n",
                "\\end{align}\n",
                "$$\n",
                "\n",
                "To follow the slope of the curve, we need to move `m` in the direction of negative gradient. However, we need to control the rate at which we go down the slope so that we do not overshoot the minimum. So we use a parameter $\\lambda$ called the `learning rate`. \n",
                "\n",
                "**Update rule of `m` and `c` using gradient descent:**\n",
                "\n",
                "$$\n",
                "\\begin{align}\n",
                "m_k &= m_{k-1} - \\lambda \\frac{\\partial l_{mse}}{\\partial m} \\\\\n",
                "c_k &= c_{k-1} - \\lambda \\frac{\\partial l_{mse}}{\\partial c} \\\\ \n",
                "\\end{align}\n",
                "$$\n",
                "\n",
                "\n",
                "## <font style=\"color:green\">3.2. Mean Absolute Error (MAE)<\/font>\n",
                "\n",
                "**The `mean absolute error (MAE)` function which is given by:**\n",
                "\n",
                "$$\n",
                "l_{mae} = \\frac{1}{N}\\sum^N_{i=1}|y_i - m x_i -c|\n",
                "$$\n",
                "\n",
                "**The above function can be re-written as the following:**\n",
                "\n",
                "$$\n",
                "l_{mae} = \\frac{1}{N}\\sum^N_{i=1}sign(y_i - m x_i -c)\\cdot (y_i - m x_i -c)\\\\\n",
                "$$\n",
                "\n",
                "Where,\n",
                "\n",
                "\\begin{equation}\n",
                "  sign(\\alpha) =\n",
                "    \\begin{cases}\n",
                "      1 & \\text{if  $\\alpha > 0$}\\\\\n",
                "      -1 & \\text{if  $\\alpha < 0$}\\\\\n",
                "      0 & \\text{otherwise}\n",
                "    \\end{cases}       \n",
                "\\end{equation}\n",
                "\n",
                "**Take partial derivatives w.r.t `m` and `c` respectively:**\n",
                "\n",
                "$$\n",
                "\\begin{align}\n",
                "\\frac{\\partial l_{mae}}{\\partial m}  &= \\frac{1}{N} \\sum^N_{i=1} sign(y_i - m x_i -c)\\cdot (- x_i) \\\\\n",
                "                                     &= -\\frac{1}{N} \\sum^N_{i=1} sign(y_i - m x_i -c)\\cdot x_i \\\\\n",
                "\\frac{\\partial l_{mae}}{\\partial c}  &= \\frac{1}{N} \\sum^N_{i=1} sign(y_i - m x_i -c)\\cdot (-1) \\\\\n",
                "                                     &= -\\frac{1}{N} \\sum^N_{i=1} sign(y_i - m x_i -c) \\\\\n",
                "\\end{align}\n",
                "$$\n",
                "\n",
                "**Update rule of `m` and `c` using gradient descent:**\n",
                "\n",
                "$$\n",
                "\\begin{align}\n",
                "m_k &= m_{k-1} - \\lambda \\frac{\\partial l_{mae}}{\\partial m} \\\\\n",
                "c_k &= c_{k-1} - \\lambda \\frac{\\partial l_{mae}}{\\partial c} \\\\ \n",
                "\\end{align}\n",
                "$$\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# <font style=\"color:green\">4. Implementation<\/font>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font style=\"color:green\">4.1. Mean Square Error (MSE) [5 Points]<\/font>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def MSE_loss(inputs, label, m, c):\n",
                "    '''\n",
                "    All arguments are defined in the training section of this notebook. \n",
                "    This function will be called from the training section.  \n",
                "    So before completing this function go through the whole notebook.\n",
                "    \n",
                "    inputs (torch.tensor): input (X)\n",
                "    labels (torch.tensor): label (Y)\n",
                "    m (float): slope of the line\n",
                "    c (float): vertical intercept of line\n",
                "    '''\n",
                "    \n",
                "    # Mean square error (loss)\n",
                "    loss = None\n",
                "    \n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "    \n",
                "    return loss\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Test your code before submitting it using the below code cell.**\n",
                "\n",
                "For given input:\n",
                "```\n",
                "X = torch.tensor([-0.0374,  2.6822, -4.1152])\n",
                "Y = torch.tensor([ 5.1765, 14.1513, -8.2802])\n",
                "m = 2\n",
                "c = 3\n",
                "```\n",
                "Output:\n",
                "```\n",
                "Mean square error (MSE): 15.95\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "X = torch.tensor([-0.0374,  2.6822, -4.1152])\n",
                "Y = torch.tensor([ 5.1765, 14.1513, -8.2802])\n",
                "m = 2\n",
                "c = 3\n",
                "\n",
                "mse_loss = MSE_loss(X, Y, m, c)\n",
                "\n",
                "print('Mean square error (MSE): {0:.2f}'.format(mse_loss))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Mean Square Error (MSE)",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font style=\"color:green\">4.2. Mean Absolute Error (MAE) [5 Points]<\/font>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def MAE_loss(inputs, label, m, c):\n",
                "    '''\n",
                "    All arguments are defined in the training section of this notebook. \n",
                "    This function will be called from the training section.  \n",
                "    So before completing this function go through the whole notebook.\n",
                "    \n",
                "    inputs (torch.tensor): input (X)\n",
                "    labels (torch.tensor): label (Y)\n",
                "    m (float): slope of the line\n",
                "    c (float): vertical intercept of line\n",
                "    '''\n",
                "    \n",
                "    # Mean absolute error (loss)\n",
                "    loss = None\n",
                "    \n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "    \n",
                "    return loss\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Test your code before submitting it using the below code cell.**\n",
                "\n",
                "For given input:\n",
                "```\n",
                "X = torch.tensor([-0.0374,  2.6822, -4.1152])\n",
                "Y = torch.tensor([ 5.1765, 14.1513, -8.2802])\n",
                "m = 2\n",
                "c = 3\n",
                "```\n",
                "Output:\n",
                "```\n",
                "Mean absolute error (MAE): 3.70\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "X = torch.tensor([-0.0374,  2.6822, -4.1152])\n",
                "Y = torch.tensor([ 5.1765, 14.1513, -8.2802])\n",
                "m = 2\n",
                "c = 3\n",
                "\n",
                "mae_loss = MAE_loss(X, Y, m, c)\n",
                "\n",
                "print('Mean absolute error (MAE): {0:.2f}'.format(mae_loss))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Mean Absolute Error (MAE)",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font style=\"color:green\">4.3. Gradients for MSE [10 Points]<\/font>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def gradient_wrt_m_and_c_mse(inputs, labels, m, c):\n",
                "    \n",
                "    '''\n",
                "    All arguments are defined in the training section of this notebook. \n",
                "    This function will be called from the training section.  \n",
                "    So before completing this function go through the whole notebook.\n",
                "    \n",
                "    inputs (torch.tensor): input (X)\n",
                "    labels (torch.tensor): label (Y)\n",
                "    m (float): slope of the line\n",
                "    c (float): vertical intercept of line\n",
                "    '''\n",
                "    # gradient w.r.t to m is g_m \n",
                "    g_m = None\n",
                "    \n",
                "    # gradient w.r.t to c is g_c\n",
                "    g_c = None\n",
                "    \n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "    \n",
                "    return g_m, g_c"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Test your code before submitting it using the below code cell.**\n",
                "\n",
                "For given input:\n",
                "```\n",
                "X = torch.tensor([-0.0374,  2.6822, -4.1152])\n",
                "Y = torch.tensor([ 5.1765, 14.1513, -8.2802])\n",
                "m = 2\n",
                "c = 3\n",
                "```\n",
                "Output:\n",
                "```\n",
                "Gradient wrt m (for MSE): -18.66\n",
                "Gradient wrt c (for MSE): -3.33\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "X = torch.tensor([-0.0374,  2.6822, -4.1152])\n",
                "Y = torch.tensor([ 5.1765, 14.1513, -8.2802])\n",
                "m = 2\n",
                "c = 3\n",
                "\n",
                "gm, gc = gradient_wrt_m_and_c_mse(X, Y, m, c)\n",
                "\n",
                "print('Gradient wrt m (for MSE): {0:.2f}'.format(gm))\n",
                "print('Gradient wrt c (for MSE): {0:.2f}'.format(gc))    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Gradients for MSE wrt m",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Gradients for MSE wrt c",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font style=\"color:green\">4.4. Gradients for MAE [10 Points]<\/font>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def gradient_wrt_m_and_c_mae(inputs, labels, m, c):\n",
                "    \n",
                "    '''\n",
                "    All arguments are defined in the training section of this notebook. \n",
                "    This function will be called from the training section.  \n",
                "    So before completing this function go through the whole notebook.\n",
                "    \n",
                "    inputs (torch.tensor): input (X)\n",
                "    labels (torch.tensor): label (Y)\n",
                "    m (float): slope of the line\n",
                "    c (float): vertical intercept of line\n",
                "    '''\n",
                "    \n",
                "    # gradient w.r.t to m is g_m \n",
                "    g_m = None\n",
                "    \n",
                "    # gradient w.r.t to c is g_c\n",
                "    g_c = None\n",
                "    \n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "    \n",
                "    return g_m, g_c\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Test your code before submitting it using the below code cell.**\n",
                "\n",
                "For given input:\n",
                "```\n",
                "X = torch.tensor([-0.0374,  2.6822, -4.1152])\n",
                "Y = torch.tensor([ 5.1765, 14.1513, -8.2802])\n",
                "m = 2\n",
                "c = 3\n",
                "```\n",
                "Output:\n",
                "```\n",
                "Gradient wrt m (for MAE): -2.25\n",
                "Gradient wrt c (for MAE): -0.33\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "X = torch.tensor([-0.0374,  2.6822, -4.1152])\n",
                "Y = torch.tensor([ 5.1765, 14.1513, -8.2802])\n",
                "m = 2\n",
                "c = 3\n",
                "\n",
                "gm, gc = gradient_wrt_m_and_c_mae(X, Y, m, c)\n",
                "\n",
                "print('Gradient wrt m (for MAE): {0:.2f}'.format(gm))\n",
                "print('Gradient wrt c (for MAE): {0:.2f}'.format(gc))    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Gradients for MAE wrt m",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Gradients for MAE wrt c",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "def update_m_and_c(m, c, g_m, g_c, lr):\n",
                "    '''\n",
                "    All arguments are defined in the training section of this notebook. \n",
                "    This function will be called from the training section.  \n",
                "    So before completing this function go through the whole notebook.\n",
                "    \n",
                "    g_m = gradient w.r.t to m\n",
                "    c_m = gradient w.r.t to c\n",
                "    '''\n",
                "    updated_m = m -  lr * g_m\n",
                "    updated_c = c - lr * g_c\n",
                "    \n",
                "    return updated_m, updated_c"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font style=\"color:green\">4.5. Training<\/font>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Function for loss plot.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "def plot_loss(loss):\n",
                "    fig = plt.figure()\n",
                "    \n",
                "    plt.subplot(1, 2, 1)\n",
                "    plt.plot(range(len(loss[0])), loss[0], color='k')\n",
                "    \n",
                "    plt.xlabel('iterations')\n",
                "    plt.ylabel('loss')\n",
                "    plt.title('MSE Loss')\n",
                "    \n",
                "    plt.subplot(1, 2, 2)\n",
                "    plt.plot(range(len(loss[1])), loss[1], color='r')\n",
                "    \n",
                "    plt.xlabel('iterations')\n",
                "    plt.ylabel('loss')\n",
                "    plt.title('MAE Loss')\n",
                "    plt.show()\n",
                "    \n",
                "    return"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Function for display intermediate training.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "def display_training(X, Y_origin, Y_label, loss, m, c, iteration):\n",
                "    print('Iteration: {}, \\nLoss_mse: {:.3f}, m_mse: {:.3f}, c_mse: {:.3f}\\nLoss_mae: {:.3f}, m_mae: {:.3f},' \n",
                "          'c_mae: {:.3f}'.format(iteration, loss[0][-1], m[0], c[0], loss[1][-1], m[1], c[1]))\n",
                "    \n",
                "    # Prediction for trained with MSE loss\n",
                "    y_pred_mse = m[0] * X + c[0]\n",
                "    \n",
                "    # Prediction for trained with MAE loss\n",
                "    y_pred_mae = m[1] * X + c[1]\n",
                "    \n",
                "    # plots\n",
                "    \n",
                "    # points plot\n",
                "    plt.plot(X, Y_label, '.', color='g')\n",
                "    \n",
                "    # Line for which data is generated\n",
                "    plt.plot(X, Y_origin, color='b', label='Line corresponding to m={0:.2f}, c={1:.2f}'.\n",
                "             format(m_line, c_line), linewidth=3)\n",
                "    \n",
                "    # Line learned with MSE loss\n",
                "    plt.plot(X, y_pred_mse, color='k', label='Line corresponding to m_mse={0:.2f}, c_learned={1:.2f}'.\n",
                "             format(m[0], c[0]), linewidth=3)\n",
                "    \n",
                "    # Line learned with MSE loss\n",
                "    plt.plot(X, y_pred_mae, color='r', label='Line corresponding to m_mae={0:.2f}, c_learned={1:.2f}'.\n",
                "             format(m[1], c[1]), linewidth=3)\n",
                "    \n",
                "    \n",
                "    plt.title(\"Iteration : {}\".format(iteration))\n",
                "    plt.legend()\n",
                "\n",
                "    plt.ylabel('y')\n",
                "    plt.xlabel('x')\n",
                "    plt.show()\n",
                "    \n",
                "    return"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**The training function**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "def train(inputs, labels, labels_origin, initial_m, initial_c, grad_fun_m_c_list, loss_fun_list, lr=0.01, \n",
                "          batch_size=10, epoch=10, display_count=20):\n",
                "    \n",
                "    loss = dict()\n",
                "    m = dict()\n",
                "    c = dict()\n",
                "    \n",
                "    for i in range(len(grad_fun_m_c_list)):\n",
                "        loss[i] = []\n",
                "        m[i] = initial_m\n",
                "        c[i] = initial_c\n",
                "        \n",
                "    num_batches = int(len(inputs)\/batch_size)\n",
                "    \n",
                "    for i in range(epoch):\n",
                "        \n",
                "        shuffle_indices = torch.randint(0, len(inputs), (len(inputs),))\n",
                "        \n",
                "        for j in range(num_batches):\n",
                "            \n",
                "            X = inputs[shuffle_indices[j*batch_size:j*batch_size+batch_size]]\n",
                "            Y = labels[shuffle_indices[j*batch_size:j*batch_size+batch_size]]\n",
                "            \n",
                "            for k, grad_m_c in enumerate(grad_fun_m_c_list):\n",
                "                g_m, g_c = grad_m_c(X, Y, m[k], c[k])\n",
                "                \n",
                "                m[k], c[k] = update_m_and_c(m[k], c[k], g_m, g_c, lr)\n",
                "                l = loss_fun_list[k](inputs, labels, m[k], c[k])\n",
                "                loss[k].append(l)\n",
                "            \n",
                "            if j % display_count == 0:\n",
                "                iteration = i * num_batches + j\n",
                "                display_training(inputs, labels_origin, labels, loss, m, c, iteration)\n",
                "                \n",
                "    final_iteration = (epoch-1) * num_batches + num_batches - 1\n",
                "                \n",
                "    return m, c, loss, final_iteration"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Training.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "scrolled": true,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# inputs\n",
                "inputs = x\n",
                "\n",
                "# output\/labels\n",
                "labels = y_label\n",
                "\n",
                "# labels around y\n",
                "labels_origin = y\n",
                "\n",
                "# epoch \n",
                "epoch=20\n",
                "\n",
                "# learning rate\n",
                "lr = 0.005\n",
                "\n",
                "# batch size\n",
                "batch_size=10\n",
                "\n",
                "# dislpay plot count\n",
                "display_count=40\n",
                "\n",
                "# inital m\n",
                "initial_m = 2\n",
                "\n",
                "# initail c\n",
                "initial_c = 1\n",
                "\n",
                "grad_fun_m_c_list = [gradient_wrt_m_and_c_mse, gradient_wrt_m_and_c_mae]\n",
                "\n",
                "loss_fun_list = [MSE_loss, MAE_loss]\n",
                "\n",
                "m, c, loss, final_iteration = train(inputs, labels, labels_origin, initial_m, initial_c, grad_fun_m_c_list, \n",
                "                                    loss_fun_list, lr, batch_size, epoch, display_count)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "print('{0}\\nFinal plots\\n{0}'.format('--------------------------'))\n",
                "\n",
                "display_training(inputs, labels_origin, labels, loss, m, c, iteration=final_iteration)\n",
                "\n",
                "plot_loss(loss)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**In the above plot, we can observe that the line learned with mean square error deviated more compare to mean absolute error.**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8",
            "language": "python",
            "name": "python38"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}